{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Brazilian Names with N-gram Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Any\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from ibge import load_ibge_name_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130356"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_ibge_name_data()\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'maria', 'freq': 11734129},\n",
       " {'name': 'jose', 'freq': 5754529},\n",
       " {'name': 'ana', 'freq': 3089858},\n",
       " {'name': 'joao', 'freq': 2984119},\n",
       " {'name': 'antonio', 'freq': 2576348}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique characters\n",
    "chars = sorted(set(\"\".join([x[\"name\"] for x in data])))\n",
    "n_chars = len(chars)\n",
    "\n",
    "# Create a mapping from characters to indices and vice versa\n",
    "i_to_c = dict(enumerate([\".\"] + chars))\n",
    "c_to_i = {v: k for k, v in i_to_c.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', '.', '.', 'r'),\n",
       " ('.', '.', 'r', 'a'),\n",
       " ('.', 'r', 'a', 'f'),\n",
       " ('r', 'a', 'f', 'a'),\n",
       " ('a', 'f', 'a', 'e'),\n",
       " ('f', 'a', 'e', 'l'),\n",
       " ('a', 'e', 'l', '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ngrams(name: str, n: int) -> Iterable[tuple]:\n",
    "    name = (n - 1)*\".\" + name + \".\"\n",
    "\n",
    "    return zip(*[name[i:] for i in range(n)])\n",
    "\n",
    "list(get_ngrams(\"rafael\", n=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data_into_ngram_tensors(\n",
    "    data: list[dict[str, Any]], \n",
    "    n: int\n",
    ") -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    assert n > 1\n",
    "\n",
    "    input_idxs = []\n",
    "    target_idxs = []\n",
    "    freqs = []\n",
    "\n",
    "    for x in tqdm(data):\n",
    "        name = x[\"name\"]\n",
    "        freq = x[\"freq\"]\n",
    "\n",
    "        for chars in get_ngrams(name, n):\n",
    "            input_idxs.append([c_to_i[c] for c in chars[:-1]])\n",
    "            target_idxs.append(c_to_i[chars[-1]])\n",
    "            freqs.append(freq)\n",
    "\n",
    "    X = F.one_hot(torch.tensor(input_idxs), num_classes=n_chars + 1).float()\n",
    "    X = X.reshape(X.shape[0], X.shape[1]*X.shape[2])\n",
    "\n",
    "    y = F.one_hot(torch.tensor(target_idxs), num_classes=n_chars + 1).float()\n",
    "\n",
    "    sample_weights = torch.tensor(freqs, dtype=torch.float32)\n",
    "    sample_weights /= sample_weights.sum()\n",
    "\n",
    "    return X, y, sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf07ca7c97d2414bb44f535ceb502eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1051060, 135]), torch.Size([1051060, 27]), torch.Size([1051060]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 6\n",
    "X, y, sample_weights = encode_data_into_ngram_tensors(data, n)\n",
    "\n",
    "X.shape, y.shape, sample_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 | loss=99.0252\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m H1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(X \u001b[38;5;241m@\u001b[39m W1)\n\u001b[0;32m      6\u001b[0m logits \u001b[38;5;241m=\u001b[39m H1 \u001b[38;5;241m@\u001b[39m W2\n\u001b[1;32m----> 7\u001b[0m nll \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m (nll \u001b[38;5;241m*\u001b[39m sample_weights)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m25\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\rladeira\\miniconda3\\envs\\env_torch\\Lib\\site-packages\\torch\\nn\\functional.py:2996\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   2991\u001b[0m         reduced \u001b[38;5;241m=\u001b[39m reduced \u001b[38;5;241m/\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   2993\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reduced\n\u001b[1;32m-> 2996\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcross_entropy\u001b[39m(\n\u001b[0;32m   2997\u001b[0m     \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[0;32m   2998\u001b[0m     target: Tensor,\n\u001b[0;32m   2999\u001b[0m     weight: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3000\u001b[0m     size_average: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3001\u001b[0m     ignore_index: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m   3002\u001b[0m     reduce: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3003\u001b[0m     reduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3004\u001b[0m     label_smoothing: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m   3005\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m   3006\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the cross entropy loss between input logits and target.\u001b[39;00m\n\u001b[0;32m   3007\u001b[0m \n\u001b[0;32m   3008\u001b[0m \u001b[38;5;124;03m    See :class:`~torch.nn.CrossEntropyLoss` for details.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3069\u001b[0m \u001b[38;5;124;03m        >>> loss.backward()\u001b[39;00m\n\u001b[0;32m   3070\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   3071\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, target, weight):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "W1 = torch.randn((n_chars + 1)*(n-1), 256, requires_grad=True)\n",
    "W2 = torch.randn((256, n_chars + 1), requires_grad=True)\n",
    "\n",
    "for i in range(50 + 1):\n",
    "    H1 = F.relu(X @ W1)\n",
    "    logits = H1 @ W2\n",
    "    \n",
    "    nll = F.cross_entropy(logits, y, reduction=\"none\")\n",
    "    loss = (nll * sample_weights).sum()\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        print(f\"epoch={i} | loss={loss.item():.4f}\")\n",
    "\n",
    "    W1.grad = None\n",
    "    W2.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    W1.data += -10*W1.grad\n",
    "    W2.data += -10*W2.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = []\n",
    "input_idxs = [0]*(n - 1)\n",
    "\n",
    "while True:\n",
    "    x_enc = F.one_hot(torch.tensor(input_idxs), num_classes=n_chars + 1).float()\n",
    "    x_enc = x_enc.reshape(1, x_enc.shape[0]*x_enc.shape[1])\n",
    "\n",
    "    H1 = F.relu(x_enc @ W1)\n",
    "    logits = H1 @ W2\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    i = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "    if i == 0:\n",
    "        break\n",
    "    else:\n",
    "        chars.append(i_to_c[i])\n",
    "        input_idxs = input_idxs[1:] + [i]\n",
    "\n",
    "name = ''.join(chars)\n",
    "name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
